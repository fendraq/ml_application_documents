# Exploring Pub Lay Net Assignment

## Purpose
This project is an exploration of how to prepare a large dataset for model training with the purpose of identifying title pages and text elements.

## Steps taken

1. **pln_data_preprocessing.py**  
   Reads and converts the original JSON annotation file to a DataFrame.

2. **pln_delete_unused_data.ipynb**  
   Filters the DataFrame to keep only rows matching available document files.

3. **pln_add_title_page.ipynb**  
   Adds a new column indicating if a page is a title page (True/False) based on the file name.

4. **pln_title_df.ipynb**  
   Removes all columns except `file_name` and `title_page`, keeping only unique entries.

5. **pln_image_downscaling.ipynb**  
   Preprocesses and downscales images to 128x128 pixels for faster model training.

6. **pln_mini_batch.ipynb**  
   Extracts a mini-batch of 500 observations for exploratory model training with GridSearchCV.

7. **pln_exploratory_model_training.ipynb**  
   Exploratory model training and comparison of RandomForestClassifier, KNeighborsClassifier, SVC, and LogisticRegression. On mini_batch.

8. **pln_exploratory_model_training_rfc.ipynb**  
   Creates a data and prediction pipeline for RandomForestClassifier based on previous findings. On mini_batch.

9. **pln_exploratory_model_training_knc.ipynb**  
   Creates a data and prediction pipeline for KNeighborsClassifier based on previous findings. On mini_batch.

10. **pln_observation_prediction_knc_rfc.ipynb**
    Creates a data and prediction pipeline for RandomForestClassifier together with KNeighborsClassifier and the ensemble_prediction where each models positive prediction is prioritized over a negative prediction. On mini_batch.

---

## Final Model Training Scripts

Located in the `pln_model_training_scripts` directory:

- **pln_first_page_model_128x128.py**  
  Script for training ensemble models (e.g., RandomForestClassifier and KNeighborsClassifier) on the 128x128 downscaled image dataset to classify title pages.

- **pln_first_page_model_128x128_pca.py**
    Script for training ensemble models (e.g., RandomForestClassifier and KNeighborsClassifier) on the 128x128 downscaled image dataset to classify title pages. Included with PCA for faster training.

---

## Data Frames

The following data frames are generated by the scripts and notebooks in the folder *data_preprocessing*:

- **df_annotations.parquet**  
  Original annotation data from the dataset.

- **df_categories.parquet**  
  Original categories data from the dataset.

- **df_images.parquet**  
  Original image metadata from the dataset.

- **df_full.parquet**  
  Merged dataset containing annotations, categories, and images.

- **df_full_filtered.parquet**  
  Filtered dataset containing only images available from Kaggle.

- **df_full_filtered_with_title.parquet**  
  Filtered dataset with an added column indicating title pages (True/False).

- **df_title_page_classification.parquet**  
  Dataset containing only unique `file_name` and `title_page` columns for classification.

---

## Processed images

The following ndarrays are generated by scripts and notebooks in the folder *image_preprocessing*:

- **pln_X_features_raw_128x128.npy**  
  Numpy array of downscaled images (128x128 pixels), generated by the image preprocessing script.

- **pln_y_labels.npy**  
  Labels for the downscaled images.

- **pln_X_amall_features_raw_128x128.npy**
    A mini-batch of 500 observations, X.

- **pln_y_small_labels.npy**
    A mini-batch of 500 labels, y.

---

## Trained Models

The following models are trained and saved using the scripts and notebooks:

- **RandomForestClassifier**
- **KNeighborsClassifier**
- **SVC**
- **LogisticRegression**
- **Combined model of RFC and KNC**

All models are generated and evaluated using the exploratory and pipeline notebooks above.

## Other files
- ****